{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/26 11:43:32 WARN Utils: Your hostname, ubuntu-hadoop resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "23/02/26 11:43:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/26 11:43:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "sc = SparkContext(\"local[*]\")\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "import pandas as pd  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "from pyspark.ml import Pipeline\n",
    "#evaluation\n",
    "from pyspark.mllib.evaluation import MultilabelMetrics\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_metrics_l(ml_model,test_data):\n",
    "    predictions = ml_model.transform(test_data).cache()\n",
    "    predictionAndLabels = predictions.select(\"label\",\"prediction\").rdd.map(lambda x: (float(x[0]), float(x[1]))).cache()\n",
    "    # Print some predictions vs labels\n",
    "    # print(predictionAndLabels.take(10))\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    # Overall statistics\n",
    "    precision = metrics.precision(1.0)\n",
    "    recall = metrics.recall(1.0)\n",
    "    f1Score = metrics.fMeasure(1.0)\n",
    "    print(f\"Precision = {precision:.4f} Recall = {recall:.4f} F1 Score = {f1Score:.4f}\")\n",
    "    print(\"Confusion matrix \\n\", metrics.confusionMatrix().toArray().astype(int))\n",
    "    return precision, recall, f1Score, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|emotion|label|              text_c|               words|            filtered|         rawFeatures|         featuresIDF|\n",
      "+--------------------+-------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|im feeling rather...|sadness|    1|  feel rather rot...|[, , feel, rather...|[, , feel, rather...|(1000,[0,1,42,102...|(1000,[0,1,42,102...|\n",
      "|im updating my bl...|sadness|    1|  update   blog b...|[, , update, , , ...|[, , update, , , ...|(1000,[0,1,117,34...|(1000,[0,1,117,34...|\n",
      "|i never make her ...|sadness|    1|  never make she ...|[, , never, make,...|[, , never, make,...|(1000,[0,1,2,4,9,...|(1000,[0,1,2,4,9,...|\n",
      "|i left with my bo...|    joy|    0|  leave with   bo...|[, , leave, with,...|[, , leave, , , b...|(1000,[0,1,39,249...|(1000,[0,1,39,249...|\n",
      "|i was feeling a l...|sadness|    1|  be feel   littl...|[, , be, feel, , ...|[, , feel, , , li...|(1000,[0,1,11,17,...|(1000,[0,1,11,17,...|\n",
      "+--------------------+-------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# read the PySpark DataFrame from the Parquet file\n",
    "df_training_m1 = spark.read.parquet(\"data/transformed_training.parquet\")\n",
    "df_testing_m1 = spark.read.parquet(\"data/transformed_test.parquet\")\n",
    "df_val_m1 = spark.read.parquet(\"data/transformed_val.parquet\")\n",
    "df_training_m1.cache()\n",
    "df_testing_m1.cache()\n",
    "df_val_m1.cache()\n",
    "print(df_testing_m1.show(5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVM - OneVSrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def liniearSVMMaker(df, df_val):\n",
    "    classifier = LinearSVC(maxIter=10, regParam=0.1, featuresCol = \"featuresIDF\", weightCol=\"weight\", labelCol=\"label\")\n",
    "    # Define OneVsRest strategy\n",
    "    ovr = OneVsRest(classifier=classifier, labelCol=\"label\", featuresCol=\"featuresIDF\", weightCol=\"weight\")\n",
    "    start = time.time()\n",
    "    pipeline = Pipeline(stages=[ovr])\n",
    "    model = pipeline.fit(df)\n",
    "    training_time = time.time()-start\n",
    "    precision_svm, recall_svm , f1Score_svm,  metrics = m_metrics_l(model,df_val)\n",
    "    return precision_svm, recall_svm, f1Score_svm, metrics, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/26 11:44:00 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/02/26 11:44:00 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "23/02/26 11:44:00 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "23/02/26 11:44:00 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hicran/Documents/emotions-detector/virtualenv_emotions/lib/python3.10/site-packages/pyspark/sql/context.py:157: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "[Stage 164:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.8836 Recall = 0.8556 F1 Score = 0.8694\n",
      "Confusion matrix \n",
      " [[671  47  43  30  79  23]\n",
      " [ 22 486  25  19   6  10]\n",
      " [  6   8 205   6   3   2]\n",
      " [  3   7   2 157   1  13]\n",
      " [  2   2   0   0  88   0]\n",
      " [  0   0   0   0   1  33]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "precision_svm, recall_svm, f1Score_svm, metrics, training_time_svm = liniearSVMMaker(df= df_training_m1, df_val=df_val_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.261017084121704"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_time_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(type(training_time_svm))\n",
    "print(type(precision_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+------------+---------+------+-------+\n",
      "|          dataModel|modelName|trainingTime|precision|recall|f1Score|\n",
      "+-------------------+---------+------------+---------+------+-------+\n",
      "|countVectorizer+iDF|      svm|       31.26|     0.88|  0.86|   0.87|\n",
      "+-------------------+---------+------------+---------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_df = spark.createDataFrame([(\"countVectorizer+iDF\",\n",
    "                                     \"svm\", \n",
    "                                    round(training_time_svm,2),\n",
    "                                    round(precision_svm,2), \n",
    "                                     round(recall_svm,2), \n",
    "                                     round(f1Score_svm,2))], \n",
    "                                     [\"dataModel\", \"modelName\", \"trainingTime\", \"precision\",\"recall\", \"f1Score\"])\n",
    "\n",
    "results_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "def logRegmaker(df, df_val):\n",
    "    cassifier = LogisticRegression(maxIter=10, regParam=0.1, featuresCol = \"featuresIDF\", weightCol=\"weight\")\n",
    "    start = time.time()\n",
    "    pipeline = Pipeline(stages=[cassifier])\n",
    "    print(f\"Training started.\")\n",
    "    model = pipeline.fit(df)\n",
    "    training_time = time.time()-start\n",
    "    precision, recall , f1Score,  metrics = m_metrics_l(model,df_val)\n",
    "    return precision, recall, f1Score, metrics, training_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started.\n",
      "Precision = 0.8964 Recall = 0.8016 F1 Score = 0.8464\n",
      "Confusion matrix \n",
      " [[678  47  47  32  74  31]\n",
      " [ 21 493  39  28  18  16]\n",
      " [  3   4 188   6   4   1]\n",
      " [  1   4   1 146   1  10]\n",
      " [  1   2   0   0  80   0]\n",
      " [  0   0   0   0   1  23]]\n"
     ]
    }
   ],
   "source": [
    "precision_lr, recall_lr , f1Score_lr , metrics_lr, training_time_lr = logRegmaker(df= df_training_m1, df_val=df_val_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= results_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[len(df.index)]= [\"countVectorizer+iDF\",\n",
    "                                     \"lr\", training_time_lr, precision_lr, recall_lr, f1Score_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataModel</th>\n",
       "      <th>modelName</th>\n",
       "      <th>trainingTime</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>countVectorizer+iDF</td>\n",
       "      <td>svm</td>\n",
       "      <td>31.260000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>countVectorizer+iDF</td>\n",
       "      <td>lr</td>\n",
       "      <td>1.183459</td>\n",
       "      <td>0.896364</td>\n",
       "      <td>0.801626</td>\n",
       "      <td>0.846352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dataModel modelName  trainingTime  precision    recall   f1Score\n",
       "0  countVectorizer+iDF       svm     31.260000   0.880000  0.860000  0.870000\n",
       "1  countVectorizer+iDF        lr      1.183459   0.896364  0.801626  0.846352"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "def nBMaker(df, df_val):\n",
    "    nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\", featuresCol = \"featuresIDF\", weightCol=\"weight\")\n",
    "    # nb_model = nb.fit(df_training_m1)\n",
    "    start = time.time()\n",
    "    pipeline = Pipeline(stages=[nb])\n",
    "    print(f\"Training started.\")\n",
    "    model = pipeline.fit(df)\n",
    "    training_time = time.time()-start\n",
    "    precision, recall , f1Score,  metrics = m_metrics_l(model,df_val)\n",
    "    return precision, recall, f1Score, metrics, training_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hicran/Documents/emotions-detector/virtualenv_emotions/lib/python3.10/site-packages/pyspark/sql/context.py:157: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.8527 Recall = 0.8257 F1 Score = 0.8390\n",
      "Confusion matrix \n",
      " [[586  23  21   6  30   7]\n",
      " [ 34 469  29  17  11   8]\n",
      " [ 14  15 209   8   5   2]\n",
      " [ 23  16  10 169   3  13]\n",
      " [ 35  16   3   4 128   0]\n",
      " [ 12  11   3   8   1  51]]\n"
     ]
    }
   ],
   "source": [
    "precision_nb, recall_nb, f1Score_nb, metrics_nb, training_time_nb = nBMaker(df=df_training_m1, df_val=df_val_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[len(df.index)]= [\"countVectorizer+iDF\",\n",
    "                                     \"nb\", training_time_nb, precision_nb, recall_nb, f1Score_nb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataModel</th>\n",
       "      <th>modelName</th>\n",
       "      <th>trainingTime</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>countVectorizer+iDF</td>\n",
       "      <td>svm</td>\n",
       "      <td>31.260000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>countVectorizer+iDF</td>\n",
       "      <td>lr</td>\n",
       "      <td>1.183459</td>\n",
       "      <td>0.896364</td>\n",
       "      <td>0.801626</td>\n",
       "      <td>0.846352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>countVectorizer+iDF</td>\n",
       "      <td>nb</td>\n",
       "      <td>0.349570</td>\n",
       "      <td>0.852727</td>\n",
       "      <td>0.825704</td>\n",
       "      <td>0.838998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dataModel modelName  trainingTime  precision    recall   f1Score\n",
       "0  countVectorizer+iDF       svm     31.260000   0.880000  0.860000  0.870000\n",
       "1  countVectorizer+iDF        lr      1.183459   0.896364  0.801626  0.846352\n",
       "2  countVectorizer+iDF        nb      0.349570   0.852727  0.825704  0.838998"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenv_emotions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7781f8813e32d1f6628649145f89b2312aa40072746c548f9037e213846e288f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
